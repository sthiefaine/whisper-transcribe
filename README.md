# ğŸ¤ Whisper Service - La BoÃ®te de Chocolat

Service de transcription audio utilisant Whisper.cpp pour le podcast "La BoÃ®te de Chocolat".

## ğŸš€ DÃ©ploiement

### DÃ©marrage Rapide (RecommandÃ©)
```bash
# Cloner le projet
git clone https://github.com/votre-username/laboitedechocolat-whisper.git
cd laboitedechocolat-whisper

# DÃ©marrage automatique
npm start

# Test rapide
npm run test-quick
```

### Avec Docker Compose (Local)
```bash
# DÃ©marrer les services
npm run up

# VÃ©rifier les logs
npm run logs
```

### Avec Railway (RecommandÃ©)
1. Connectez votre repo GitHub Ã  Railway
2. Railway dÃ©tectera automatiquement le Dockerfile
3. DÃ©ployez !

### Avec Render
1. CrÃ©ez un nouveau Web Service
2. Connectez votre repo GitHub
3. SÃ©lectionnez "Docker" comme runtime
4. DÃ©ployez !

## ğŸ“¡ API

### Transcription
```bash
POST /transcribe
Content-Type: application/json

{
  "audio_url": "https://example.com/audio.mp3",
  "language": "fr",
  "model": "base"
}
```

**RÃ©ponse :**
```json
{
  "success": true,
  "transcription": "Voici le texte transcrit...",
  "model": "whisper-base-fr",
  "processing_time": 12.34,
  "file_size": 1024000
}
```

### Health Check
```bash
GET /health
```

**RÃ©ponse :**
```json
{
  "status": "healthy",
  "timestamp": "2024-01-01T12:00:00",
  "model": "whisper-base-fr",
  "version": "1.0.0"
}
```

### Lister les ModÃ¨les
```bash
GET /models
```

**RÃ©ponse :**
```json
{
  "models": ["ggml-base.bin"],
  "current_model": "ggml-base.bin"
}
```

## ğŸ“¤ Gestion des longues transcriptions

Pour les fichiers audio gÃ©nÃ©rant une transcription longue (plus de 2000 caractÃ¨res), lâ€™API **ne renvoie pas tout le texte dans la rÃ©ponse**. Ã€ la placeâ€¯:

- La transcription est stockÃ©e cÃ´tÃ© serveur dans `/var/log/whisper/`.
- Lâ€™API renvoie une clÃ© `transcription_url` permettant de tÃ©lÃ©charger le texte.
- Pour les transcriptions courtes, le texte est renvoyÃ© directement dans la rÃ©ponse.

### Exemple de rÃ©ponse pour une longue transcription
```json
{
  "success": true,
  "transcription_url": "https://api.ton-domaine.com/transcriptions/12345678-90ab-cdef-1234-567890abcdef.txt",
  "model": "whisper-large-fr",
  "processing_time": 123.45,
  "file_size": 12345678
}
```

### Pour rÃ©cupÃ©rer la transcription

Il suffit dâ€™accÃ©der Ã  lâ€™URL fournieâ€¯:
```
GET /transcriptions/<transcription_id>.txt
```

---

## ğŸ”€ DiffÃ©rence entre `/transcribe` et `/transcribe/file`

- **`/transcribe/file`** : upload direct dâ€™un fichier audio (multipart/form-data)
- **`/transcribe`** : envoi dâ€™une URL dâ€™audio Ã  tÃ©lÃ©charger (JSON)

Les deux routes appliquent la mÃªme logiqueâ€¯: stockage + URL pour les longues transcriptions, texte direct pour les courtes.

## ğŸ”§ Configuration

### Variables d'environnement
- `PORT` : Port du serveur (dÃ©faut: 8080)
- `MAX_FILE_SIZE` : Taille max des fichiers (dÃ©faut: 100MB)
- `WHISPER_PATH` : Chemin vers Whisper.cpp (dÃ©faut: /opt/whisper.cpp)

### ModÃ¨les Disponibles
- `base` : ModÃ¨le de base (recommandÃ©)
- `small` : ModÃ¨le plus petit, plus rapide
- `medium` : ModÃ¨le plus grand, plus prÃ©cis
- `large` : ModÃ¨le le plus prÃ©cis (nÃ©cessite plus de RAM)

## ğŸ“Š Monitoring

- Health check automatique toutes les 30s
- Logs structurÃ©s avec timestamps
- MÃ©triques de performance (temps de traitement)
- Gestion des erreurs et timeouts

## ğŸ› ï¸ DÃ©veloppement

### Scripts NPM
Le projet utilise npm pour centraliser tous les scripts :

```bash
# Voir tous les scripts disponibles
npm run help

# Commandes principales
npm start          # DÃ©marrage automatique
npm run test-quick # Test rapide
npm run logs       # Voir les logs
npm run reset      # Reset complet
```

### Fichier de Test
Le projet inclut un fichier de test audio `data/avatar_test_short.mp3` (145MB) pour tester la transcription :
```bash
# VÃ©rifier le fichier
ls -lh data/avatar_test_short.mp3

# Test rapide
npm run test-quick
```

### Structure du Projet
```
laboitedechocolat-whisper/
â”œâ”€â”€ Dockerfile              # Image Docker
â”œâ”€â”€ docker-compose.yml      # Orchestration
â”œâ”€â”€ server.py              # Serveur Flask
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â”œâ”€â”€ nginx.conf            # Configuration Nginx
â”œâ”€â”€ .gitignore           # Fichiers ignorÃ©s
â”œâ”€â”€ README.md            # Documentation
â””â”€â”€ scripts/             # Scripts utilitaires
    â”œâ”€â”€ install-whisper.sh
    â””â”€â”€ download-models.sh
```

### Tests Locaux

#### Test avec Docker
```bash
# DÃ©marrer les services
npm run up

# Test rapide
npm run test-quick

# Test complet
npm test

# VÃ©rifier la santÃ©
npm run test-health
```

#### Test sans Docker (dÃ©veloppement)
```bash
# Mode dÃ©veloppement
npm run dev

# Dans un autre terminal, tester
npm run test-local
```

#### Test manuel avec curl
```bash
# Test avec fichier local
curl -X POST http://localhost:8080/transcribe/file \
  -F "audio_file=@data/avatar_test_short.mp3" \
  -F "language=fr" \
  -F "model=base"

# Test avec URL
curl -X POST http://localhost:8080/transcribe \
  -H "Content-Type: application/json" \
  -d '{"audio_url": "https://example.com/test.mp3"}'
```

## ğŸ”’ SÃ©curitÃ©

- Utilisateur non-root dans le conteneur
- Validation des URLs d'entrÃ©e
- Limitation de la taille des fichiers
- Timeouts configurÃ©s
- CORS configurÃ© (Ã  adapter en production)

## ğŸ“ˆ Performance

- ModÃ¨le base : ~1GB RAM, ~10-30s pour 1min d'audio
- OptimisÃ© pour les podcasts franÃ§ais
- Support des formats audio courants (MP3, WAV, M4A)
- Traitement asynchrone possible

## ğŸ¤ IntÃ©gration

### Avec votre projet principal
```typescript
// Dans votre projet laboitedechocolat
const WHISPER_API_URL = process.env.WHISPER_API_URL || "http://localhost:8080";

const response = await fetch(`${WHISPER_API_URL}/transcribe`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    audio_url: audioFileUrl,
    language: 'fr',
    model: 'base'
  })
});
```

## ğŸ› DÃ©pannage

### ProblÃ¨mes Courants

1. **ModÃ¨le non trouvÃ©**
   ```bash
   # VÃ©rifier que le modÃ¨le est tÃ©lÃ©chargÃ©
   docker-compose exec whisper-api ls /opt/whisper.cpp/models/
   ```

2. **Timeout de transcription**
   - Augmenter les timeouts dans nginx.conf
   - VÃ©rifier la taille du fichier audio

3. **Erreur de compilation**
   ```bash
   # Reconstruire l'image
   docker-compose build --no-cache
   ```

## ğŸ“ Licence

MIT License - Libre d'utilisation pour le projet "La BoÃ®te de Chocolat" 

## ğŸ“¦ ModÃ¨les Disponibles
- `tiny` : ModÃ¨le ultra-rapide, peu prÃ©cis
- `base` : ModÃ¨le de base (recommandÃ© pour la plupart des usages)
- `small` : Plus prÃ©cis, un peu plus lent
- `medium` : TrÃ¨s prÃ©cis, plus lent
- `large` : Le plus prÃ©cis, trÃ¨s gourmand en RAM/CPU
- `large-v2` : Variante amÃ©liorÃ©e du modÃ¨le large

## ğŸ“¥ TÃ©lÃ©charger tous les modÃ¨les Whisper

Pour tÃ©lÃ©charger tous les modÃ¨les sur votre serveur (aprÃ¨s dÃ©ploiement) :

```bash
bash scripts/download-all-models.sh
```

Les modÃ¨les seront placÃ©s dans `/opt/whisper.cpp/models` (ou le volume Docker correspondant).

## ğŸ“¡ Exemple d'appel API avec un modÃ¨le spÃ©cifique

### Transcription avec le modÃ¨le large

```bash
curl -X POST http://localhost:8080/transcribe/file \
  -F "audio_file=@data/avatar_test_short.mp3" \
  -F "language=fr" \
  -F "model=large"
```

## ğŸ³ Astuce Docker/Coolify

- Les modÃ¨les tÃ©lÃ©chargÃ©s sont persistants si vous utilisez un volume Docker pour `/opt/whisper.cpp/models`.
- AprÃ¨s chaque dÃ©ploiement, vÃ©rifiez la prÃ©sence des modÃ¨les avec :
  ```bash
  docker-compose exec whisper-api ls /opt/whisper.cpp/models/
  ``` 

## Gestion asynchrone des transcriptions (proposition pour Ã©volution future)

### Objectif
Permettre de traiter des fichiers audio trÃ¨s longs sans risque de timeout HTTP, en lanÃ§ant la transcription en tÃ¢che de fond et en permettant au client de suivre lâ€™avancement puis de rÃ©cupÃ©rer le rÃ©sultat.

### Principe gÃ©nÃ©ral
1. **POST `/transcribe-async`**
   - Le client envoie un fichier audio ou une URL.
   - Le serveur crÃ©e une tÃ¢che asynchrone (thread ou process Python).
   - Le serveur rÃ©pond immÃ©diatement avec un `task_id` unique.

2. **GET `/transcription-status/<task_id>`**
   - Le client interroge lâ€™Ã©tat de la tÃ¢che (`pending`, `processing`, `done`, `error`).
   - Lâ€™Ã©tat est stockÃ© en mÃ©moire (dictionnaire partagÃ©) ou dans un petit fichier JSON.

3. **GET `/transcriptions/<fichier>.txt`**
   - Quand la tÃ¢che est terminÃ©e, le client peut tÃ©lÃ©charger la transcription comme aujourdâ€™hui.

### Exemple de logique cÃ´tÃ© serveur (pseudo-code)

```python
# Dictionnaire global pour stocker lâ€™Ã©tat des tÃ¢ches
TASKS = {}

@app.route('/transcribe-async', methods=['POST'])
def transcribe_async():
    # 1. GÃ©nÃ©rer un task_id unique
    # 2. Stocker lâ€™Ã©tat initial (pending)
    # 3. Lancer un thread/process qui exÃ©cute la transcription et met Ã  jour lâ€™Ã©tat
    # 4. Retourner le task_id
    pass

@app.route('/transcription-status/<task_id>', methods=['GET'])
def transcription_status(task_id):
    # Retourner lâ€™Ã©tat de la tÃ¢che (pending, processing, done, error)
    pass
```

### Avantages
- Plus de timeout HTTP, mÃªme pour des fichiers trÃ¨s longs.
- Facile Ã  intÃ©grer Ã  lâ€™API existante.
- Peut Ã©voluer vers une solution plus robuste (Celery/Redis) si besoin.

### Limites
- Si le serveur redÃ©marre, les tÃ¢ches en mÃ©moire sont perdues (prÃ©voir une persistance sur disque si besoin).
- Pour une forte charge ou plusieurs serveurs, prÃ©fÃ©rer une file dâ€™attente externe (ex: Redis).

### Pour aller plus loin
- Ajouter une persistance des tÃ¢ches sur disque (fichier JSON par tÃ¢che).
- Passer Ã  Celery/Redis pour la scalabilitÃ©.
- Ajouter des notifications (webhook, email) quand la transcription est prÃªte.

--- 

## Formats de sortie disponibles

Lâ€™API permet de choisir le format de sortie de la transcriptionâ€¯:
- `txt` : texte brut (par dÃ©faut)
- `srt` : sous-titres SRT (avec timestamps, compatible vidÃ©o)
- `vtt` : WebVTT (pour affichage synchronisÃ© sur le web)

### Utilisation du paramÃ¨tre `output_format`

Ajoutez le champ `output_format` dans votre requÃªte JSON ou formulaireâ€¯:

#### Exemple pour `/transcribe` ou `/transcribe-async`
```json
{
  "audio_url": "https://.../fichier.mp3",
  "model": "base",
  "language": "fr",
  "output_format": "vtt"
}
```

#### Exemple pour `/transcribe/file` (upload)
- Ajoutez un champ `output_format` dans le formulaire (valeur : `txt`, `srt` ou `vtt`).

### RÃ©sultat
- Le lien de transcription pointera vers le fichier gÃ©nÃ©rÃ© au bon formatâ€¯:
  - `.txt` pour le texte brut
  - `.srt` pour les sous-titres SRT
  - `.vtt` pour le format WebVTT

### Affichage synchronisÃ© (paroles, karaokÃ©, etc.)
- Utilisez le format `srt` ou `vtt` pour afficher les paroles synchronisÃ©es avec lâ€™audio dans un lecteur compatible (HTML5, Video.js, Plyr, etc.).
- Le format `txt` ne contient que le texte sans timestamps.

--- 